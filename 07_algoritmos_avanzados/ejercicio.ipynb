{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Análisis de Sentimientos en Reseñas de Productos\n",
    "\n",
    "## Objetivo\n",
    "Crear un sistema de análisis de sentimientos utilizando una arquitectura LSTM para clasificar reseñas de productos como positivas o negativas.\n",
    "\n",
    "## Descripción del Problema\n",
    "Tienes un dataset de 5000 reseñas de productos con las siguientes características:\n",
    "- Texto de la reseña\n",
    "- Calificación (1-5 estrellas)\n",
    "- Longitud variable de texto\n",
    "\n",
    "## Tareas a Realizar\n",
    "\n",
    "### 1. Preparación de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar las bibliotecas necesarias\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Cargar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Cargar datos (ejemplo)\n",
    "data = pd.read_csv('reviews.csv')\n",
    "#https://www.kaggle.com/code/chirag9073/amazon-fine-food-reviews-sentiment-analysis/notebook?select=Reviews.csv\n",
    "\n",
    "# Convertir calificaciones a sentimiento binario\n",
    "# 4-5 estrellas = positivo (1)\n",
    "# 1-2 estrellas = negativo (0)\n",
    "data['sentiment'] = (data['rating'] >= 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Procesamiento de Texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y ajustar el tokenizador\n",
    "max_words = 5000  # Tamaño del vocabulario\n",
    "max_len = 100     # Longitud máxima de cada reseña\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "\n",
    "# Convertir texto a secuencias\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = data['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementación del Modelo LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential([\n",
    "    Embedding(max_words, 32, input_length=max_len),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Prácticos\n",
    "\n",
    "1. **Implementación Base:**\n",
    "   - Implementa el código proporcionado\n",
    "   - Entrena el modelo con los datos\n",
    "   - Evalúa su rendimiento básico\n",
    "\n",
    "2. **Mejoras Sugeridas:**\n",
    "   - Añade regularización para evitar overfitting\n",
    "   - Implementa early stopping\n",
    "   - Prueba diferentes tamaños de embedding\n",
    "\n",
    "3. **Análisis y Visualización:**\n",
    "   - Grafica la curva de aprendizaje\n",
    "   - Visualiza la matriz de confusión\n",
    "   - Analiza ejemplos de predicciones\n",
    "\n",
    "## Preguntas de Reflexión\n",
    "\n",
    "1. ¿Por qué usamos una arquitectura LSTM en lugar de una RNN simple?\n",
    "2. ¿Cómo afecta el tamaño del embedding al rendimiento del modelo?\n",
    "3. ¿Qué papel juega el Dropout en este modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
