{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Calidad de Vinos usando Deep Learning\n",
    "\n",
    "## Objetivo\n",
    "Crear un modelo de deep learning que prediga la calidad de vinos basándose en sus características fisicoquímicas.\n",
    "\n",
    "## Dataset\n",
    "Utilizaremos el dataset de Wine Quality del UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv), que contiene las siguientes características:\n",
    "\n",
    "1. fixed acidity\n",
    "2. volatile acidity\n",
    "3. citric acid\n",
    "4. residual sugar\n",
    "5. chlorides\n",
    "6. free sulfur dioxide\n",
    "7. total sulfur dioxide\n",
    "8. density\n",
    "9. pH\n",
    "10. sulphates\n",
    "11. alcohol\n",
    "\n",
    "Variable objetivo:\n",
    "- quality (puntaje entre 0 y 10)\n",
    "\n",
    "## Tareas a realizar\n",
    "\n",
    "1. **Carga y exploración de datos**\n",
    "   - Cargar el dataset\n",
    "   - Realizar un análisis exploratorio básico\n",
    "   - Visualizar distribuciones y correlaciones\n",
    "\n",
    "2. **Preprocesamiento**\n",
    "   - Manejar valores faltantes si existen\n",
    "   - Normalizar las características\n",
    "   - Dividir en conjuntos de entrenamiento y prueba\n",
    "\n",
    "3. **Construcción del modelo**\n",
    "   - Diseñar una arquitectura de red neuronal apropiada\n",
    "   - Compilar el modelo con las métricas adecuadas\n",
    "\n",
    "4. **Entrenamiento y evaluación**\n",
    "   - Entrenar el modelo\n",
    "   - Evaluar su rendimiento\n",
    "   - Visualizar resultados\n",
    "\n",
    "## Retos adicionales\n",
    "- Comparar diferentes arquitecturas de red\n",
    "- Implementar validación cruzada\n",
    "- Realizar ajuste de hiperparámetros\n",
    "- Convertir el problema en clasificación binaria (vinos buenos vs malos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',sep=\";\")\n",
    "df = pd.read_csv('C:/Users/albaro/Documents/DataSets/winequality-red.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detectar nulos\n",
    "nulos = df.isnull()\n",
    "print(nulos.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.098940</td>\n",
       "      <td>0.567548</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283186</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.143573</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.209581</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283186</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.133556</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.169611</td>\n",
       "      <td>0.508811</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.191617</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.584071</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.105175</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.582232</td>\n",
       "      <td>0.330709</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.098940</td>\n",
       "      <td>0.567548</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.141593</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.130217</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.134276</td>\n",
       "      <td>0.354626</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.294521</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.083472</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.159011</td>\n",
       "      <td>0.370778</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.257485</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0.150442</td>\n",
       "      <td>0.267123</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.120141</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.251497</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.359589</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.105175</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.134276</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.227545</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.130137</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.091820</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.127208</td>\n",
       "      <td>0.397944</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.247788          0.397260         0.00        0.068493   0.106845   \n",
       "1          0.283186          0.520548         0.00        0.116438   0.143573   \n",
       "2          0.283186          0.438356         0.04        0.095890   0.133556   \n",
       "3          0.584071          0.109589         0.56        0.068493   0.105175   \n",
       "4          0.247788          0.397260         0.00        0.068493   0.106845   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594       0.141593          0.328767         0.08        0.075342   0.130217   \n",
       "1595       0.115044          0.294521         0.10        0.089041   0.083472   \n",
       "1596       0.150442          0.267123         0.13        0.095890   0.106845   \n",
       "1597       0.115044          0.359589         0.12        0.075342   0.105175   \n",
       "1598       0.123894          0.130137         0.47        0.184932   0.091820   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0                0.140845              0.098940  0.567548  0.606299   \n",
       "1                0.338028              0.215548  0.494126  0.362205   \n",
       "2                0.197183              0.169611  0.508811  0.409449   \n",
       "3                0.225352              0.190813  0.582232  0.330709   \n",
       "4                0.140845              0.098940  0.567548  0.606299   \n",
       "...                   ...                   ...       ...       ...   \n",
       "1594             0.436620              0.134276  0.354626  0.559055   \n",
       "1595             0.535211              0.159011  0.370778  0.614173   \n",
       "1596             0.394366              0.120141  0.416300  0.535433   \n",
       "1597             0.436620              0.134276  0.396476  0.653543   \n",
       "1598             0.239437              0.127208  0.397944  0.511811   \n",
       "\n",
       "      sulphates   alcohol  quality  \n",
       "0      0.137725  0.153846      0.4  \n",
       "1      0.209581  0.215385      0.4  \n",
       "2      0.191617  0.215385      0.4  \n",
       "3      0.149701  0.215385      0.6  \n",
       "4      0.137725  0.153846      0.4  \n",
       "...         ...       ...      ...  \n",
       "1594   0.149701  0.323077      0.4  \n",
       "1595   0.257485  0.430769      0.6  \n",
       "1596   0.251497  0.400000      0.6  \n",
       "1597   0.227545  0.276923      0.4  \n",
       "1598   0.197605  0.400000      0.6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizar\n",
    "df_normalized = (df - df.min()) / (df.max() - df.min())  # Min-Max Scaling\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir en entrenamiento y prueba\n",
    "X = df.drop('quality', axis='columns')\n",
    "y = df.quality\n",
    "\n",
    "xTrain,xTest,yTrain,yTest = train_test_split(X,y, train_size = 0.7,shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\albaro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m363\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,211</span> (12.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,211\u001b[0m (12.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,211</span> (12.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,211\u001b[0m (12.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# diseñar una red neuronal apropiada\n",
    "\n",
    "# Número de características en la entrada\n",
    "input_dim = 11  # Porque tienes 11 columnas en tu dataset\n",
    "\n",
    "# Número de clases en la salida (por ejemplo, si \"quality\" tiene 6 clases: 0,1,2,3,4,5,6,7,8,9,10)\n",
    "num_classes = 11  # Ajusta según el número real de clases en tu dataset\n",
    "\n",
    "# Definir el modelo secuencial\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),  # Capa oculta 1\n",
    "    Dense(32, activation='relu'),  # Capa oculta 2\n",
    "    Dense(num_classes, activation='softmax')  # Capa de salida con softmax\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Ver resumen del modelo\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 31.8620 - mae: 5.5784 - val_loss: 31.5555 - val_mae: 5.5519\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0578 - mae: 5.5102 - val_loss: 31.5466 - val_mae: 5.5519\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6858 - mae: 5.5676 - val_loss: 31.5390 - val_mae: 5.5519\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.8757 - mae: 5.5882 - val_loss: 31.5373 - val_mae: 5.5519\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8968 - mae: 5.5900 - val_loss: 31.5366 - val_mae: 5.5519\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.2073 - mae: 5.6101 - val_loss: 31.5364 - val_mae: 5.5519\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.5581 - mae: 5.5543 - val_loss: 31.5362 - val_mae: 5.5519\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5722 - mae: 5.5613 - val_loss: 31.5361 - val_mae: 5.5519\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3156 - mae: 5.5363 - val_loss: 31.5361 - val_mae: 5.5519\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9181 - mae: 5.5842 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8708 - mae: 5.5854 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.5896 - mae: 5.5616 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5717 - mae: 5.5602 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6610 - mae: 5.5651 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5290 - mae: 5.5584 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7899 - mae: 5.5805 - val_loss: 31.5360 - val_mae: 5.5519\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9097 - mae: 5.5863 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5970 - mae: 5.5624 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3741 - mae: 5.5485 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5081 - mae: 5.5545 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7069 - mae: 5.5703 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5414 - mae: 5.5563 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5013 - mae: 5.5502 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 24/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0347 - mae: 5.5109 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 25/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2727 - mae: 5.5353 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 26/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.3015 - mae: 5.6243 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 27/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6223 - mae: 5.5646 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 28/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6015 - mae: 5.5595 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 29/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5954 - mae: 5.5696 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 30/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7787 - mae: 5.5793 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 31/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.0362 - mae: 5.6009 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 32/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5710 - mae: 5.5632 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 33/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8775 - mae: 5.5805 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 34/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1353 - mae: 5.5226 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 35/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6087 - mae: 5.5648 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 36/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3755 - mae: 5.5422 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 37/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6300 - mae: 5.5717 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 38/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8019 - mae: 5.5788 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 39/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4883 - mae: 5.5509 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 40/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6722 - mae: 5.5730 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 41/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1958 - mae: 5.5290 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 42/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9711 - mae: 5.5949 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 43/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7062 - mae: 5.5733 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 44/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3315 - mae: 5.5409 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 45/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6919 - mae: 5.5734 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 46/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7629 - mae: 5.5755 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 47/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9392 - mae: 5.5952 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 48/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4955 - mae: 5.5545 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 49/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6761 - mae: 5.5677 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 50/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1082 - mae: 5.5197 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 51/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7247 - mae: 5.5729 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 52/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4990 - mae: 5.5531 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 53/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1401 - mae: 5.5184 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 54/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8579 - mae: 5.5890 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 55/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4493 - mae: 5.5458 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 56/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8069 - mae: 5.5838 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 57/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5806 - mae: 5.5620 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 58/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2999 - mae: 5.5390 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 59/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.1638 - mae: 5.6125 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 60/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.1020 - mae: 5.6063 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 61/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.6860 - mae: 5.5730 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 62/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8440 - mae: 5.5844 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 63/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6880 - mae: 5.5699 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 64/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4514 - mae: 5.5533 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 65/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.7990 - mae: 5.5824 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 66/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4467 - mae: 5.5524 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 67/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7470 - mae: 5.5737 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 68/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3229 - mae: 5.5378 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 69/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5428 - mae: 5.5573 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 70/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3071 - mae: 5.5320 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 71/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9689 - mae: 5.5956 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 72/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5362 - mae: 5.5546 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 73/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6807 - mae: 5.5715 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 74/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1292 - mae: 5.6045 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 75/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6408 - mae: 5.5708 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 76/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4952 - mae: 5.5569 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 77/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1337 - mae: 5.5230 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 78/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8460 - mae: 5.5838 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 79/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8778 - mae: 5.5857 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 80/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4738 - mae: 5.5507 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 81/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2581 - mae: 5.5303 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 82/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.1449 - mae: 5.6159 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 83/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5151 - mae: 5.5543 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 84/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6001 - mae: 5.5624 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 85/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5980 - mae: 5.5630 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 86/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4042 - mae: 5.5475 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 87/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5102 - mae: 5.5511 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 88/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.6390 - mae: 5.5693 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 89/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 31.4721 - mae: 5.5499 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 90/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6054 - mae: 5.5661 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 91/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6141 - mae: 5.5675 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 92/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6285 - mae: 5.5714 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 93/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4307 - mae: 5.5424 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 94/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6944 - mae: 5.5713 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 95/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1303 - mae: 5.6086 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 96/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6668 - mae: 5.5685 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 97/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4692 - mae: 5.5531 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 98/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7297 - mae: 5.5724 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 99/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.0143 - mae: 5.5991 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 100/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7973 - mae: 5.5862 - val_loss: 31.5359 - val_mae: 5.5519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2386d533a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suponiendo que ya tienes tus datos preparados en X_train, y_train\n",
    "model.fit(xTrain, yTrain, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.9620 - mae: 5.5167 \n",
      "Pérdida en test: 30.8441\n",
      "Precisión en test: 5.4987\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(xTest, yTest)\n",
    "print(f\"Pérdida en test: {loss:.4f}\")\n",
    "print(f\"Precisión en test: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0787 - mae: 5.5159 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 2/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.0346 - mae: 5.6035 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 3/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6979 - mae: 5.5730 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 4/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4982 - mae: 5.5525 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 5/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7439 - mae: 5.5761 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 6/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5915 - mae: 5.5583 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 7/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3977 - mae: 5.5466 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 8/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.2637 - mae: 5.5330 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 9/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7356 - mae: 5.5741 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 10/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.0404 - mae: 5.5985 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 11/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3175 - mae: 5.5401 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 12/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3420 - mae: 5.5408 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 13/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3194 - mae: 5.5390 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 14/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5603 - mae: 5.5619 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 15/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7884 - mae: 5.5809 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 16/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1990 - mae: 5.6134 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 17/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0907 - mae: 5.5199 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 18/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6686 - mae: 5.5692 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 19/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2268 - mae: 5.5294 - val_loss: 31.5359 - val_mae: 5.5519\n",
      "Epoch 20/20\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7485 - mae: 5.5745 - val_loss: 31.5359 - val_mae: 5.5519\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Graficar precisión\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecisión entrenamiento\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecisión validación\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÉpocas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Entrenar el modelo con historial\n",
    "history = model.fit(xTrain, yTrain, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Graficar pérdida\n",
    "plt.plot(history.history['loss'], label='Pérdida entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.title('Evolución de la Pérdida')\n",
    "plt.show()\n",
    "\n",
    "# Graficar precisión\n",
    "plt.plot(history.history['accuracy'], label='Precisión entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Precisión validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.title('Evolución de la Precisión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
