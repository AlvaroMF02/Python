{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 1: Análisis de Datos de Calidad del Aire en California\n",
        "\n",
        "Utilizando el dataset de calidad del aire de California disponible en:\n",
        "https://www.kaggle.com/datasets/sogun3/uspollution\n",
        "\n",
        "O directamente del EPA (Environmental Protection Agency):\n",
        "https://aqs.epa.gov/aqsweb/airdata/download_files.html\n",
        "\n",
        "Realiza las siguientes tareas:\n",
        "\n",
        "1. Carga el dataset en un DataFrame y filtra los datos para quedarte solo con las mediciones de California\n",
        "\n",
        "2. Realiza una limpieza inicial de los datos:\n",
        "   - Identifica y maneja valores nulos\n",
        "   - Convierte las columnas de fecha al formato correcto\n",
        "   - Verifica y corrige valores atípicos\n",
        "\n",
        "3. Analiza los contaminantes principales (NO2, SO2, CO, O3):\n",
        "   - Calcula promedios mensuales por ciudad\n",
        "   - Identifica las 5 ciudades con mayores niveles de cada contaminante\n",
        "   - Determina si hay patrones estacionales\n",
        "\n",
        "4. Crea nuevas columnas derivadas:\n",
        "   - Índice de calidad del aire simplificado\n",
        "   - Clasificación por niveles de riesgo\n",
        "   - Indicadores de cumplimiento de estándares EPA\n",
        "\n",
        "5. Realiza análisis temporal:\n",
        "   - Calcula tendencias anuales\n",
        "   - Identifica días críticos (con valores extremos)\n",
        "   - Genera medias móviles semanales y mensuales\n",
        "\n",
        "6. Exporta los resultados:\n",
        "   - Guarda un resumen por ciudad en CSV\n",
        "   - Crea un archivo con los días críticos identificados\n",
        "   - Genera un reporte con las estadísticas principales\n",
        "\n",
        "Conceptos evaluados:\n",
        "- Filtrado y selección de datos\n",
        "- Manejo de fechas y series temporales\n",
        "- Agregaciones y groupby\n",
        "- Creación de nuevas variables\n",
        "- Detección de outliers\n",
        "- Exportación de resultados\n",
        "- Análisis estadístico básico\n",
        "\n",
        "Bonus:\n",
        "- Crear visualizaciones de las tendencias encontradas\n",
        "- Realizar un análisis de correlación entre contaminantes\n",
        "- Implementar un sistema de alertas basado en umbrales\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>State Code</th>\n",
              "      <th>County Code</th>\n",
              "      <th>Site Num</th>\n",
              "      <th>Address</th>\n",
              "      <th>State</th>\n",
              "      <th>County</th>\n",
              "      <th>City</th>\n",
              "      <th>Date Local</th>\n",
              "      <th>NO2 Units</th>\n",
              "      <th>...</th>\n",
              "      <th>SO2 Units</th>\n",
              "      <th>SO2 Mean</th>\n",
              "      <th>SO2 1st Max Value</th>\n",
              "      <th>SO2 1st Max Hour</th>\n",
              "      <th>SO2 AQI</th>\n",
              "      <th>CO Units</th>\n",
              "      <th>CO Mean</th>\n",
              "      <th>CO 1st Max Value</th>\n",
              "      <th>CO 1st Max Hour</th>\n",
              "      <th>CO AQI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3002</td>\n",
              "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>Maricopa</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>2000-01-01</td>\n",
              "      <td>Parts per billion</td>\n",
              "      <td>...</td>\n",
              "      <td>Parts per billion</td>\n",
              "      <td>3.000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Parts per million</td>\n",
              "      <td>1.145833</td>\n",
              "      <td>4.2</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3002</td>\n",
              "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>Maricopa</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>2000-01-01</td>\n",
              "      <td>Parts per billion</td>\n",
              "      <td>...</td>\n",
              "      <td>Parts per billion</td>\n",
              "      <td>3.000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Parts per million</td>\n",
              "      <td>0.878947</td>\n",
              "      <td>2.2</td>\n",
              "      <td>23</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3002</td>\n",
              "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>Maricopa</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>2000-01-01</td>\n",
              "      <td>Parts per billion</td>\n",
              "      <td>...</td>\n",
              "      <td>Parts per billion</td>\n",
              "      <td>2.975</td>\n",
              "      <td>6.6</td>\n",
              "      <td>23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Parts per million</td>\n",
              "      <td>1.145833</td>\n",
              "      <td>4.2</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  State Code  County Code  Site Num  \\\n",
              "0           0           4           13      3002   \n",
              "1           1           4           13      3002   \n",
              "2           2           4           13      3002   \n",
              "\n",
              "                                   Address    State    County     City  \\\n",
              "0  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona  Maricopa  Phoenix   \n",
              "1  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona  Maricopa  Phoenix   \n",
              "2  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona  Maricopa  Phoenix   \n",
              "\n",
              "   Date Local          NO2 Units  ...          SO2 Units  SO2 Mean  \\\n",
              "0  2000-01-01  Parts per billion  ...  Parts per billion     3.000   \n",
              "1  2000-01-01  Parts per billion  ...  Parts per billion     3.000   \n",
              "2  2000-01-01  Parts per billion  ...  Parts per billion     2.975   \n",
              "\n",
              "   SO2 1st Max Value  SO2 1st Max Hour SO2 AQI           CO Units   CO Mean  \\\n",
              "0                9.0                21    13.0  Parts per million  1.145833   \n",
              "1                9.0                21    13.0  Parts per million  0.878947   \n",
              "2                6.6                23     NaN  Parts per million  1.145833   \n",
              "\n",
              "   CO 1st Max Value  CO 1st Max Hour CO AQI  \n",
              "0               4.2               21    NaN  \n",
              "1               2.2               23   25.0  \n",
              "2               4.2               21    NaN  \n",
              "\n",
              "[3 rows x 29 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "usPollution = pd.read_csv(\"c:/Users/alvar/Documents/DataSets/pollution_us_2000_2016.csv\")\n",
        "usPollution.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad total de nulos: 0\n"
          ]
        }
      ],
      "source": [
        "# quitar los nulos haciendo la media\n",
        "usPollution.loc[:, 'CO AQI'] = usPollution['CO AQI'].fillna(usPollution['CO AQI'].mean())\n",
        "usPollution.loc[:, 'SO2 AQI'] = usPollution['SO2 AQI'].fillna(usPollution['SO2 AQI'].mean())\n",
        "\n",
        "# Comprobacion de nulos\n",
        "nulos=usPollution.isnull()\n",
        "total=nulos.sum()\n",
        "total_nulos = total.sum()\n",
        "print(\"Cantidad total de nulos:\", total_nulos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0          01-01-2000\n",
            "1          01-01-2000\n",
            "2          01-01-2000\n",
            "3          01-01-2000\n",
            "4          02-01-2000\n",
            "              ...    \n",
            "1746656    30-03-2016\n",
            "1746657    31-03-2016\n",
            "1746658    31-03-2016\n",
            "1746659    31-03-2016\n",
            "1746660    31-03-2016\n",
            "Name: Date Local, Length: 1746661, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Cambiar las fechas formato español\n",
        "usPollution[\"Date Local\"] = pd.to_datetime(usPollution[\"Date Local\"])           # se pasa a datetime\n",
        "usPollution[\"Date Local\"] = usPollution[\"Date Local\"].dt.strftime(\"%d-%m-%Y\")   # se formatea\n",
        "print(usPollution[\"Date Local\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columna 'County Code' tiene valores atípicos.\n",
            "Columna 'Site Num' tiene valores atípicos.\n",
            "Columna 'NO2 Mean' tiene valores atípicos.\n",
            "Columna 'NO2 1st Max Value' tiene valores atípicos.\n",
            "Columna 'NO2 AQI' tiene valores atípicos.\n",
            "Columna 'O3 Mean' tiene valores atípicos.\n",
            "Columna 'O3 1st Max Value' tiene valores atípicos.\n",
            "Columna 'O3 1st Max Hour' tiene valores atípicos.\n",
            "Columna 'O3 AQI' tiene valores atípicos.\n",
            "Columna 'SO2 Mean' tiene valores atípicos.\n",
            "Columna 'SO2 1st Max Value' tiene valores atípicos.\n",
            "Columna 'SO2 AQI' tiene valores atípicos.\n",
            "Columna 'CO Mean' tiene valores atípicos.\n",
            "Columna 'CO 1st Max Value' tiene valores atípicos.\n",
            "Columna 'CO AQI' tiene valores atípicos.\n"
          ]
        }
      ],
      "source": [
        "# Encontrar las columnas con valores atipicos\n",
        "for columna in usPollution.select_dtypes(include='number').columns:\n",
        "    Q1 = usPollution[columna].quantile(0.25)\n",
        "    Q3 = usPollution[columna].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Verificar si hay valores atípicos\n",
        "    outliers = usPollution[(usPollution[columna] < limite_inferior) | (usPollution[columna] > limite_superior)]\n",
        "    if not outliers.empty:\n",
        "        print(f\"Columna '{columna}' tiene valores atípicos.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ahora que sabemos cuales son todos los outlayers los metemos en un array\n",
        "outlayers = ['County Code','Site Num','NO2 Mean','NO2 1st Max Value','NO2 AQI','O3 Mean','O3 1st Max Value',\n",
        "             'O3 1st Max Hour','O3 AQI','SO2 Mean','SO2 1st Max Value','SO2 AQI','CO Mean','CO 1st Max Value','CO AQI']\n",
        "\n",
        "# sns.boxplot(data=usPollution[outlayers])\n",
        "# plt.title(\"Antes del tratamiento\")\n",
        "# plt.show()\n",
        "\n",
        "# reemplazar los outlayers por la media\n",
        "for columna in outlayers:\n",
        "    Q1 = usPollution[columna].quantile(0.25)\n",
        "    Q3 = usPollution[columna].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "    media = usPollution[columna].median()\n",
        "\n",
        "    # Reemplazar valores por la media\n",
        "    usPollution.loc[usPollution[columna] < limite_inferior, columna] = media\n",
        "    usPollution.loc[usPollution[columna] > limite_superior, columna] = media\n",
        "\n",
        "# sns.boxplot(data=usPollution[outlayers])\n",
        "# plt.title(\"Después del tratamiento\")\n",
        "# plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                NO2 Mean   O3 Mean  SO2 Mean   CO Mean\n",
            "City                                                  \n",
            "Albuquerque    12.327862  0.031607  0.606967  0.209757\n",
            "Alexandria     14.723212  0.029367  1.431808  0.250643\n",
            "Altoona         9.805315  0.027530  1.848689  0.153368\n",
            "Annandale      12.443023  0.028033  2.673347  0.418900\n",
            "Arden-Arcade   10.555333  0.025731  0.855301  0.334480\n",
            "...                  ...       ...       ...       ...\n",
            "Wilkes-Barre    9.379293  0.027925  2.107246  0.207660\n",
            "Wilmington     11.556340  0.026417  1.014242  0.261600\n",
            "Winston-Salem  10.938972  0.033318  2.219531  0.457841\n",
            "Winter Park     7.630252  0.026599  0.378496  0.419641\n",
            "York           12.484448  0.028238  1.850898  0.213278\n",
            "\n",
            "[144 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# 3. Analiza los contaminantes principales (NO2, SO2, CO, O3):\n",
        "# Calcula promedios mensuales por ciudad\n",
        "print(usPollution.groupby(\"City\")[[\"NO2 Mean\", \"O3 Mean\", \"SO2 Mean\", \"CO Mean\"]].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 ciudades con mas cantidad de NO2:\n",
            "             City   NO2 Mean\n",
            "1152213      Reno  35.658333\n",
            "1152212      Reno  35.658333\n",
            "1152215      Reno  35.658333\n",
            "1152214      Reno  35.658333\n",
            "1284994  New York  35.654167\n",
            "\n",
            "Top 5 ciudades con mas cantidad de O3:\n",
            "                City   O3 Mean\n",
            "891893   Victorville  0.057958\n",
            "891892   Victorville  0.057958\n",
            "1231876  Victorville  0.057958\n",
            "1231774  Victorville  0.057958\n",
            "1231772  Victorville  0.057958\n",
            "\n",
            "Top 5 ciudades con mas cantidad de SO2:\n",
            "                     City  SO2 Mean\n",
            "928910             Boston  5.427273\n",
            "928909             Boston  5.427273\n",
            "404122   East Saint Louis  5.425000\n",
            "250545           New York  5.425000\n",
            "1283917          New York  5.425000\n",
            "\n",
            "Top 5 ciudades con mas cantidad de CO:\n",
            "               City   CO Mean\n",
            "1071200     Tijuana  0.891364\n",
            "1071198     Tijuana  0.891364\n",
            "25536     San Diego  0.891304\n",
            "1492012  Long Beach  0.891304\n",
            "202785   Costa Mesa  0.891304\n"
          ]
        }
      ],
      "source": [
        "# Identifica las 5 ciudades con mayores niveles de cada contaminante\n",
        "# por cada contaminante hay que ordenar los valores y mostrar las 5 primeras ciudades\n",
        "topNO2 = usPollution.sort_values(by=\"NO2 Mean\", ascending=False).head(5)[[\"City\", \"NO2 Mean\"]]\n",
        "topO3 = usPollution.sort_values(by=\"O3 Mean\", ascending=False).head(5)[[\"City\", \"O3 Mean\"]]\n",
        "topSO2 = usPollution.sort_values(by=\"SO2 Mean\", ascending=False).head(5)[[\"City\", \"SO2 Mean\"]]\n",
        "topCO = usPollution.sort_values(by=\"CO Mean\", ascending=False).head(5)[[\"City\", \"CO Mean\"]]\n",
        "\n",
        "# Imprime los resultados\n",
        "print(\"Top 5 ciudades con mas cantidad de NO2:\")\n",
        "print(topNO2)\n",
        "\n",
        "print(\"\\nTop 5 ciudades con mas cantidad de O3:\")\n",
        "print(topO3)\n",
        "\n",
        "print(\"\\nTop 5 ciudades con mas cantidad de SO2:\")\n",
        "print(topSO2)\n",
        "\n",
        "print(\"\\nTop 5 ciudades con mas cantidad de CO:\")\n",
        "print(topCO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determina si hay patrones estacionales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Crea nuevas columnas derivadas:\n",
        "# Índice de calidad del aire simplificado\n",
        "# Clasificación por niveles de riesgo\n",
        "# Indicadores de cumplimiento de estándares EPA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Realiza análisis temporal:\n",
        "# Calcula tendencias anuales\n",
        "# Identifica días críticos (con valores extremos)\n",
        "# Genera medias móviles semanales y mensuales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Exporta los resultados:\n",
        "# Guarda un resumen por ciudad en CSV\n",
        "# Crea un archivo con los días críticos identificados\n",
        "# Genera un reporte con las estadísticas principales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 2: Análisis de Datos del Mundial de Fútbol\n",
        "\n",
        "Utilizando el dataset histórico de la FIFA World Cup disponible en:\n",
        "https://www.kaggle.com/datasets/abecklas/fifa-world-cup\n",
        "\n",
        "Desarrolla:\n",
        "1. Carga y combina los datasets de partidos y equipos usando merge\n",
        "2. Calcula estadísticas por país:\n",
        "   - Total de participaciones en mundiales\n",
        "   - Goles anotados y recibidos\n",
        "   - Victorias, derrotas y empates\n",
        "3. Identifica los 5 países más exitosos basándote en una métrica que combines\n",
        "4. Crea un DataFrame pivotado que muestre el progreso de cada país por año\n",
        "5. Genera visualizaciones para mostrar las tendencias históricas\n",
        "\n",
        "Conceptos evaluados: merge de DataFrames, pivot tables, agregaciones múltiples, creación de métricas compuestas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfFurbo = pd.read_csv(\"c:/Users/alvar/Documents/DataSets/WorldCupMatches.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcula estadísticas por país:\n",
        "# Total de participaciones en mundiales\n",
        "# Goles anotados y recibidos\n",
        "# Victorias, derrotas y empates\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Identifica los 5 países más exitosos basándote en una métrica que combines\n",
        "# 4. Crea un DataFrame pivotado que muestre el progreso de cada país por año\n",
        "# 5. Genera visualizaciones para mostrar las tendencias históricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 3: Análisis de Series Temporales de Bolsa\n",
        "\n",
        "Usando el dataset de Yahoo Finance para el índice S&P 500 (^GSPC) disponible vía pandas_datareader:\n",
        "https://finance.yahoo.com/quote/%5EGSPC/\n",
        "\n",
        "Realiza:\n",
        "1. Obtén los datos de los últimos 5 años usando pandas_datareader\n",
        "2. Calcula retornos diarios, semanales y mensuales\n",
        "3. Identifica los 10 días con mayor volatilidad\n",
        "4. Implementa una ventana móvil de 20 días para calcular:\n",
        "   - Media móvil\n",
        "   - Desviación estándar móvil\n",
        "   - Máximos y mínimos móviles\n",
        "5. Crea indicadores técnicos básicos (RSI, MACD)\n",
        "6. Genera visualizaciones de los indicadores\n",
        "\n",
        "Conceptos evaluados: series temporales, ventanas móviles, cálculos financieros, resampleo de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 4: Análisis de Datos de COVID-19\n",
        "\n",
        "Utilizando el dataset de Our World in Data sobre COVID-19:\n",
        "https://github.com/owid/covid-19-data/tree/master/public/data\n",
        "\n",
        "Desarrolla:\n",
        "1. Carga y limpia el dataset\n",
        "2. Calcula para cada país:\n",
        "   - Tasa de positividad diaria\n",
        "   - Media móvil de 7 días de casos nuevos\n",
        "   - Tiempo hasta alcanzar picos de casos\n",
        "3. Agrupa países por continente y compara métricas clave\n",
        "4. Identifica correlaciones entre variables (casos, muertes, vacunación)\n",
        "5. Crea un dashboard básico con las métricas más relevantes\n",
        "\n",
        "Conceptos evaluados: limpieza de datos, análisis por grupos, correlaciones, visualización avanzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 5: Análisis de Reseñas de Amazon\n",
        "\n",
        "Usando el dataset de reseñas de Amazon disponible en:\n",
        "https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n",
        "\n",
        "Realiza:\n",
        "1. Carga y preprocesa el dataset\n",
        "2. Analiza la distribución de puntuaciones\n",
        "3. Identifica patrones temporales en las reseñas:\n",
        "   - Evolución de puntuaciones promedio por mes/año\n",
        "   - Cambios en la longitud de las reseñas\n",
        "4. Agrupa productos por categoría y analiza diferencias en:\n",
        "   - Puntuación promedio\n",
        "   - Cantidad de reseñas\n",
        "   - Sentimiento general\n",
        "5. Crea un sistema simple de detección de reseñas potencialmente falsas basado en múltiples criterios\n",
        "\n",
        "Conceptos evaluados: text processing, análisis temporal, detección de anomalías, agregaciones complejas"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
